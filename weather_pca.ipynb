{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cad9815-526b-4017-b08b-0c018cdc7d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity\n",
    "from factor_analyzer.factor_analyzer import calculate_kmo\n",
    "import pingouin as pg\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import statsmodels.api as sm # biblioteca de modelagem estatística\n",
    "from statsmodels.iolib.summary2 import summary_col # comparação entre modelos\n",
    "from scipy.stats import pearsonr # correlações de Pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "766c2940-4c8b-48e0-aa83-6c1cc5b82c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Spark Session\n",
    "spark = SparkSession.builder.appName(\"EDA\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9eba209-5dee-4e7c-8768-97a11f814d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Data\n",
    "pandasdf = pd.read_excel('INMET_SE_SP_A771_2022.xlsx')\n",
    "df = spark.createDataFrame(pandasdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb485d41-658d-4212-9a46-c7e4ccd4bf23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns overview\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Data type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data</td>\n",
       "      <td>timestamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hora UTC</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRECIPITAÇÃO TOTAL HORÁRIO (mm)</td>\n",
       "      <td>double</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRESSAO ATMOSFERICA AO NIVEL DA ESTACAO HORARI...</td>\n",
       "      <td>double</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRESSÃO ATMOSFERICA MAX NA HORA ANT  (AUT) (mB)</td>\n",
       "      <td>double</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PRESSÃO ATMOSFERICA MIN NA HORA ANT (AUT) (mB)</td>\n",
       "      <td>double</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RADIACAO GLOBAL (Kj/m²)</td>\n",
       "      <td>double</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TEMPERATURA DO AR - BULBO SECO HORARIA (°C)</td>\n",
       "      <td>double</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TEMPERATURA DO PONTO DE ORVALHO (°C)</td>\n",
       "      <td>double</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TEMPERATURA MÁXIMA NA HORA ANT (AUT) (°C)</td>\n",
       "      <td>double</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TEMPERATURA MÍNIMA NA HORA ANT (AUT) (°C)</td>\n",
       "      <td>double</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TEMPERATURA ORVALHO MAX NA HORA ANT (AUT) (°C)</td>\n",
       "      <td>double</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TEMPERATURA ORVALHO MIN NA HORA ANT (AUT) (°C)</td>\n",
       "      <td>double</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>UMIDADE REL MAX NA HORA ANT (AUT) (%)</td>\n",
       "      <td>double</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>UMIDADE REL MIN NA HORA ANT (AUT) (%)</td>\n",
       "      <td>double</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>UMIDADE RELATIVA DO AR HORARIA (%)</td>\n",
       "      <td>double</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>VENTO DIREÇÃO HORARIA (gr) (° (gr))</td>\n",
       "      <td>double</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>VENTO RAJADA MAXIMA (m/s)</td>\n",
       "      <td>double</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>VENTO VELOCIDADE HORARIA (m/s)</td>\n",
       "      <td>double</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Column Name  Data type\n",
       "0                                                Data  timestamp\n",
       "1                                            Hora UTC     string\n",
       "2                     PRECIPITAÇÃO TOTAL HORÁRIO (mm)     double\n",
       "3   PRESSAO ATMOSFERICA AO NIVEL DA ESTACAO HORARI...     double\n",
       "4     PRESSÃO ATMOSFERICA MAX NA HORA ANT  (AUT) (mB)     double\n",
       "5      PRESSÃO ATMOSFERICA MIN NA HORA ANT (AUT) (mB)     double\n",
       "6                             RADIACAO GLOBAL (Kj/m²)     double\n",
       "7         TEMPERATURA DO AR - BULBO SECO HORARIA (°C)     double\n",
       "8                TEMPERATURA DO PONTO DE ORVALHO (°C)     double\n",
       "9           TEMPERATURA MÁXIMA NA HORA ANT (AUT) (°C)     double\n",
       "10          TEMPERATURA MÍNIMA NA HORA ANT (AUT) (°C)     double\n",
       "11     TEMPERATURA ORVALHO MAX NA HORA ANT (AUT) (°C)     double\n",
       "12     TEMPERATURA ORVALHO MIN NA HORA ANT (AUT) (°C)     double\n",
       "13              UMIDADE REL MAX NA HORA ANT (AUT) (%)     double\n",
       "14              UMIDADE REL MIN NA HORA ANT (AUT) (%)     double\n",
       "15                 UMIDADE RELATIVA DO AR HORARIA (%)     double\n",
       "16                VENTO DIREÇÃO HORARIA (gr) (° (gr))     double\n",
       "17                          VENTO RAJADA MAXIMA (m/s)     double\n",
       "18                     VENTO VELOCIDADE HORARIA (m/s)     double"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic Data Exploration\n",
    "print('Columns overview')\n",
    "pd.DataFrame(df.dtypes, columns = ['Column Name','Data type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06757c5f-202a-4089-bcad-09d49511086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the missing values\n",
    "\n",
    "# Get the column names\n",
    "column_names = df.columns\n",
    "\n",
    "# Get the numeric_columns\n",
    "numeric_columns = column_names[2:]\n",
    "\n",
    "missing_values = {} \n",
    "for index, column in enumerate(df.columns):\n",
    "    if column in numeric_columns:  # check zeroes, None, NaN\n",
    "        missing_count = df.where(col(column).isin([0,None,np.nan])).count()\n",
    "        missing_values.update({column:missing_count})\n",
    "\n",
    "missing_df = pd.DataFrame.from_dict([missing_values])\n",
    "missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d36770e-97f7-4c11-8420-2bd5b175733d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c069da-0fad-4fb4-894a-5365f00fa23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'Hora UTC' column\n",
    "df = df.drop(\"Hora UTC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0581c3af-8209-4d6d-884a-7aaaff21ee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run describe() on the PySpark DataFrame\n",
    "describe_result = df.describe()\n",
    "\n",
    "# Convert the result to a Pandas DataFrame with custom column names\n",
    "pandas_df_describe = describe_result.toPandas().rename(columns={'summary': 'Column Name', 'col1': 'Data type'})\n",
    "\n",
    "# Display the Pandas DataFrame\n",
    "pandas_df_describe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b8a5f1-2aa9-4097-84d1-8bc29529e58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avarage values for each month\n",
    "from pyspark.sql.functions import month, year, avg\n",
    "\n",
    "# Convert the 'Data' column to a date type if it's not already\n",
    "df = df.withColumn(\"Data\", df[\"Data\"].cast(\"date\"))\n",
    "\n",
    "# Extract the month and year from the 'Data' column\n",
    "df = df.withColumn(\"Month\", month(df[\"Data\"]))\n",
    "df = df.withColumn(\"Year\", year(df[\"Data\"]))\n",
    "\n",
    "# Get the numeric_columns\n",
    "numeric_columns = [column for column in df.columns if column != \"Data\" and column != \"Month\" and column != \"Year\"]\n",
    "\n",
    "# Create a list to store the aggregation expressions\n",
    "agg_exprs = [avg(column).alias(f\"Avg_{column}\") for column in numeric_columns]\n",
    "\n",
    "# Group by year and month, and calculate the average of numeric columns\n",
    "grouped_df = df.groupBy(\"Year\", \"Month\").agg(*agg_exprs)\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "grouped_df_pd = grouped_df.toPandas()\n",
    "\n",
    "grouped_df_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193c95a6-e09f-4120-a9f1-9414d05841e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Vizualisation: Temperature through 2022\n",
    "\n",
    "# Select the relevant columns\n",
    "temp_date_df = df.select(\"Data\", \"TEMPERATURA MÁXIMA NA HORA ANT (AUT) (°C)\", \"TEMPERATURA MÍNIMA NA HORA ANT (AUT) (°C)\")\n",
    "\n",
    "# Convert to Pandas DataFrame\n",
    "temp_date_df_pd = temp_date_df.toPandas()\n",
    "\n",
    "# Create the chart\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "plt.plot(temp_date_df_pd[\"Data\"], temp_date_df_pd[\"TEMPERATURA MÁXIMA NA HORA ANT (AUT) (°C)\"], label=\"Max Temperature (°C)\", color=\"red\")\n",
    "plt.plot(temp_date_df_pd[\"Data\"], temp_date_df_pd[\"TEMPERATURA MÍNIMA NA HORA ANT (AUT) (°C)\"], label=\"Min Temperature (°C)\", color=\"blue\")\n",
    "\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Temperature (°C)\")\n",
    "plt.title(\"Temperature Over the Year\")\n",
    "plt.legend()\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caafe61-e627-4ad4-aed0-d8b4d81656e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying PCA to the dataframe filtered by the month of August\n",
    "\n",
    "# Filter the rows where the month is 8\n",
    "august_df = df.filter(month(\"Data\") == 8)\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "august_df_pd = august_df.toPandas()\n",
    "\n",
    "august_df_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2774ecc-8510-4523-8a73-55d094bb0a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of rows\n",
    "num_rows = august_df.count()\n",
    "\n",
    "# Get the list of column names\n",
    "column_names = august_df.columns\n",
    "\n",
    "# Display the dimensions\n",
    "print(f\"Number of Rows: {num_rows}\")\n",
    "print(f\"Number of Columns: {len(column_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2898326-cd52-4c35-8711-50e04282d639",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8aa412-b958-4ad4-8d11-b12f1b12b729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the columns you want to calculate the averages for\n",
    "columns_to_average = [\n",
    "    ('PRESSÃO ATMOSFERICA MAX NA HORA ANT  (AUT) (mB)', 'PRESSÃO ATMOSFERICA MIN NA HORA ANT (AUT) (mB)'),\n",
    "    ('TEMPERATURA MÁXIMA NA HORA ANT (AUT) (°C)', 'TEMPERATURA MÍNIMA NA HORA ANT (AUT) (°C)'),\n",
    "    ('TEMPERATURA ORVALHO MAX NA HORA ANT (AUT) (°C)', 'TEMPERATURA ORVALHO MIN NA HORA ANT (AUT) (°C)'),\n",
    "    ('UMIDADE REL MAX NA HORA ANT (AUT) (%)', 'UMIDADE REL MIN NA HORA ANT (AUT) (%)'),\n",
    "    ('VENTO RAJADA MAXIMA (m/s)', 'VENTO VELOCIDADE HORARIA (m/s)')\n",
    "]\n",
    "\n",
    "# Create a new DataFrame to store the averages\n",
    "aug_avg_df_pd = pd.DataFrame()\n",
    "\n",
    "# Calculate and store the averages for each column pair\n",
    "for col1, col2 in columns_to_average:\n",
    "    average_col_name = f'AVERAGE_{col1}_{col2}'  # Create a new column name\n",
    "    aug_avg_df_pd[average_col_name] = (august_df_pd[col1] + august_df_pd[col2]) / 2\n",
    "\n",
    "# Select the columns you want to keep from the original DataFrame\n",
    "columns_to_keep = ['PRECIPITAÇÃO TOTAL HORÁRIO (mm)',\n",
    "                   'RADIACAO GLOBAL (Kj/m²)']\n",
    "\n",
    "# Select those columns from the original DataFrame\n",
    "selected_columns = august_df_pd[columns_to_keep]\n",
    "\n",
    "# Concatenate the selected columns with the DataFrame containing averages\n",
    "aug_df_pd = pd.concat([selected_columns, aug_avg_df_pd], axis=1)\n",
    "\n",
    "# Show de df\n",
    "aug_df_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04aad65-2a35-41f8-a716-8a238ee3b357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing PCA \n",
    "\n",
    "# Matrix of correlations between variables\n",
    "matriz_corr = pg.rcorr(aug_df_pd, method = 'pearson', upper = 'pval', decimals = 4, pval_stars = {0.01: '***', 0.05: '**', 0.10: '*'})\n",
    "matriz_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2435c4b-b781-40ac-b368-42bfb448cd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to plot the same information\n",
    "\n",
    "corr = aug_df_pd.corr()\n",
    "\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "cmap = sns.diverging_palette(230, 20, n=256, as_cmap=True)\n",
    "\n",
    "sns.heatmap(aug_df_pd.corr(), \n",
    "            mask=mask, \n",
    "            cmap=cmap, \n",
    "            vmax=1, \n",
    "            vmin = -.25,\n",
    "            center=0,\n",
    "            square=True, \n",
    "            linewidths=.5,\n",
    "            annot = True,\n",
    "            fmt='.3f', \n",
    "            annot_kws={'size': 16},\n",
    "            cbar_kws={\"shrink\": .75})\n",
    "\n",
    "plt.title('Matriz de correlação')\n",
    "plt.tight_layout()\n",
    "ax.tick_params(axis = 'x', labelsize = 14)\n",
    "ax.tick_params(axis = 'y', labelsize = 14)\n",
    "ax.set_ylim(len(corr))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d48a1b0-69aa-4394-8c02-922191459cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bartlett test\n",
    "bartlett, p_value = calculate_bartlett_sphericity(aug_df_pd)\n",
    "print(f'Bartlett statistic: {bartlett}')\n",
    "print(f'p-value : {p_value}')\n",
    "\n",
    "# KMO Statisticskmo_all\n",
    "kmo_model = calculate_kmo(aug_df_pd)\n",
    "print(f'kmo_model : {kmo_model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e840c6-1677-449c-956e-f131fe4a721a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the PCA (preliminary procedure)\n",
    "fa = FactorAnalyzer()\n",
    "fa.fit(aug_df_pd)\n",
    "\n",
    "# Getting the Eigenvalues ​​(eigenvalues)\n",
    "ev, v = fa.get_eigenvalues()\n",
    "print(ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bca8d20-300a-479d-b25e-cec4d88c0107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaiser Criterion\n",
    "\n",
    "# Check eigenvalues ​​with values ​​greater than 1\n",
    "# There are three components above 1\n",
    "\n",
    "# Parameterizing the PCA for two factors (eigenvalues ​​> 1)\n",
    "fa.set_params(n_factors = 3, method = 'principal', rotation = None)\n",
    "fa.fit(aug_df_pd)\n",
    "\n",
    "# Eigenvalues, variances and accumulated variances\n",
    "eigen_fatores = fa.get_factor_variance()\n",
    "eigen_fatores\n",
    "\n",
    "eigen_table = pd.DataFrame(eigen_fatores)\n",
    "eigen_table.columns = [f\"Fator {i+1}\" for i, v in enumerate(eigen_table.columns)]\n",
    "eigen_table.index = ['Eigenvalue','Variance', 'Accumulated Variance']\n",
    "eigen_table = eigen_table.T\n",
    "\n",
    "eigen_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2800a235-2258-45cf-8bc8-56a276ed7f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining factor loadings\n",
    "factor_loads = fa.loadings_\n",
    "\n",
    "load_table = pd.DataFrame(factor_loads)\n",
    "load_table.columns = [f\"Fator {i+1}\" for i, v in enumerate(load_table.columns)]\n",
    "load_table.index = aug_df_pd.columns\n",
    "load_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c99c388-5fd5-4eda-b682-671dffa68271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining commonalities\n",
    "commonalities = fa.get_communalities()\n",
    "\n",
    "commonalities_table = pd.DataFrame(commonalities)\n",
    "commonalities_table.columns = ['Commonalities']\n",
    "commonalities_table.index = aug_df_pd.columns\n",
    "commonalities_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b18453d-8b5b-4f77-b6a5-d014bd48cfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factor results for the dataset observations (predict)\n",
    "predict_fatores= pd.DataFrame(fa.transform(aug_df_pd))\n",
    "predict_fatores.columns =  [f\"Fator {i+1}\" for i, v in enumerate(predict_fatores.columns)]\n",
    "\n",
    "predict_fatores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5a3a05-0630-4874-8845-f3974f2d36a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding to dataset\n",
    "aug_df_pd_pf = pd.concat([aug_df_pd.reset_index(drop=True), predict_fatores], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a51f22b-ff5d-4491-9105-61f8dbc353d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying factor scores\n",
    "scores = fa.weights_\n",
    "\n",
    "table_scores = pd.DataFrame(scores)\n",
    "table_scores.columns = [f\"Fator {i+1}\" for i, v in enumerate(table_scores.columns)]\n",
    "table_scores.index = aug_df_pd.columns\n",
    "table_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f347b12-612d-4721-b3f4-c49286129bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between factors\n",
    "\n",
    "# Next, it appears that the correlation between the factors is zero (orthogonal)\n",
    "corr_fator = pg.rcorr(aug_df_pd_pf[['Fator 1','Fator 2', 'Fator 3']], method = 'pearson', upper = 'pval', decimals = 4, pval_stars = {0.01: '***', 0.05: '**', 0.10: '*'})\n",
    "corr_fator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e160ac2-d97b-4dd5-a096-8acddf2e18ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a ranking\n",
    "aug_df_pd_pf['Ranking'] = 0\n",
    "\n",
    "for index, item in enumerate(list(eigen_table.index)):\n",
    "    variancia = eigen_table.loc[item]['Variance']\n",
    "\n",
    "    aug_df_pd_pf['Ranking'] = aug_df_pd_pf['Ranking'] + aug_df_pd_pf[eigen_table.index[index]]*variancia\n",
    "    \n",
    "aug_df_pd_pf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c578375-04a2-4641-943b-ca81c3721932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart of factor loadings and their variances in the main components\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "table_loads_chart = load_table.reset_index()\n",
    "\n",
    "plt.scatter(table_loads_chart['Fator 1'], table_loads_chart['Fator 2'], s=30)\n",
    "\n",
    "def label_point(x, y, val, ax):\n",
    "    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)\n",
    "    for i, point in a.iterrows():\n",
    "        ax.text(point['x'] + 0.05, point['y'], point['val'])\n",
    "\n",
    "label_point(x = table_loads_chart['Fator 1'],\n",
    "            y = table_loads_chart['Fator 2'],\n",
    "            val = table_loads_chart['index'],\n",
    "            ax = plt.gca()) \n",
    "\n",
    "plt.axhline(y=0, color='black', ls='--')\n",
    "plt.axvline(x=0, color='black', ls='--')\n",
    "plt.ylim([-1.5,1.5])\n",
    "plt.xlim([-1.5,1.5])\n",
    "plt.title(f\"{eigen_table.shape[0]} main components that explain {(eigen_table['Variance'].round(2).sum())*100}% of variance\", fontsize=14)\n",
    "plt.xlabel(f\"PC 1: {(eigen_table.iloc[0]['Variance'].round(2))*100}% of variance explained\", fontsize=14)\n",
    "plt.ylabel(f\"PC 2: {(eigen_table.iloc[1]['Variance'].round(2))*100}% of variance explained\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee03fa5-337e-49e7-b2d4-4a5aca5604ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of the accumulated variance of the principal components\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "plt.title(f\"{eigen_table.shape[0]} main components that explain {(eigen_table['Variance'].round(2).sum())*100}% of variance\", fontsize=14)\n",
    "sns.barplot(x=eigen_table.index, y=eigen_table['Variance'], data=eigen_table, color='green')\n",
    "plt.xlabel(\"Main components\", fontsize=14)\n",
    "plt.ylabel(\"Percentage of variance explained\", fontsize=14)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
